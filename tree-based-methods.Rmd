---
title: "Heart Disease Prediction"
subtitle: "Tree-Based Methods"
author: "Alex Kim"
date: "December 6, 2018"
subtitle: 'Stats 202: Data Mining and Analysis'
---

```{R message=FALSE}
library(tidyverse)
library(tree)
library(randomForest)
library(gbm)
```

***

# Importing the Data

```{R message=FALSE}
# Initial import
train_data <- read_csv("data/train_data.csv")
test_data <- read_csv("data/test_data.csv")

train_data$Status <- as.factor(train_data$Status)  # Make response explicitly categorical

# Remove ID's; create ID vector for test
train_data <- train_data[-12]
test_ids <- as.vector(test_data$Id)
test_data <- test_data[-11]
```

# Subtraining and Subtest Datasets

```{R}
set.seed(1)

subtrain_size <- floor(0.5 * nrow(train_data))
subtrain_indexes <- sample(x = 1:nrow(train_data), size = subtrain_size)

subtrain <- train_data[subtrain_indexes,]
subtest <- train_data[-subtrain_indexes,]

rm(subtrain_size, subtrain_indexes)
```

***

# Simple Classification Tree

```{R}
simple_tree <- tree(Status ~ ., data = subtrain)
summary(simple_tree)

predictions <- predict(simple_tree, subtest, type = "class")
mean(predictions != subtest$Status)  # Average error
```

# Cross Validated Pruning

**Tree size 5** is optimal after several CV runs

```{R}
cv_tree <- cv.tree(simple_tree, FUN = prune.misclass)
cv_tree$size[which.min(cv_tree$dev)]

# Plot CV error vs tree size
# plot(cv_tree$size, cv_tree$dev, type = "b", xlab = "Tree Size", ylab = "CV Classification Error")
```

```{R}
pruned_tree <- prune.misclass(simple_tree, best = 7)

predictions <- predict(pruned_tree, subtest, type = "class")
mean(predictions != subtest$Status)  # Average error
```

## Export for Kaggle

```{R}
# Re-train pruned tree on full training set
simple_tree <- tree(Status ~ ., data = train_data)

cv_tree <- cv.tree(simple_tree, FUN = prune.misclass)
cv_tree$size[which.min(cv_tree$dev)]

pruned_tree <- prune.misclass(simple_tree, best = 5)

# Predict
predictions <- predict(pruned_tree, test_data, type = "class")

# Generate file for Kaggle
predictions <- if_else(predictions == 1, TRUE, FALSE)
kaggle_submission <- tibble(Id = test_ids, Category = predictions)
write_csv(kaggle_submission, "data/submission.csv")
```

# Bagging

```{R}
num_predictors <- ncol(subtrain) - 1
bagging_trees <- randomForest(Status ~ ., data = subtrain, mtry =  num_predictors, importance = TRUE)

predictions <- predict(bagging_trees, subtest, type = "class")
mean(predictions != subtest$Status)
```

# Random Forest

***mtry* = 2** generally seems to perform well.

```{R}
num_predictors <- ncol(subtrain) - 1
error_values <- tibble(m = integer(), error = double())

for(m in 1:num_predictors) {
  rf <- randomForest(Status ~ ., data = subtrain, mtry =  m, importance = TRUE)

  predictions <- predict(rf, subtest, type = "class")
  error <- mean(predictions != subtest$Status)
  
  error_values <- add_row(error_values, m = m, error = error)
}

# plot(x = error_values$m, y = error_values$error, type = "b")
```

```{R}
rf <- randomForest(Status ~ ., data = subtrain, mtry =  2, importance = TRUE)

predictions <- predict(rf, subtest, type = "class")
error <- mean(predictions != subtest$Status)

error
```

# Boosting

```{R}
set.seed(1)

n_trees <- 5000
boosted <- gbm(Status ~ ., data = subtrain, distribution = "bernoulli", n.trees = n_trees, interaction.depth = 4, shrinkage = 0.2)

posterior_p_1 <- predict(boosted, newdata = subtest, n.trees = n_trees)
predictions <- if_else(posterior_p_1 > 0.5, 1, 0)

mean(predictions != subtest$Status)
```